---
title: "CEVE 543 Fall 2025 Pset 2"

author: Jonah Schaechter
date: "2025-11-18"
type: "Pset"
module: 2

engine: julia


format:
  html:
    toc: true
    toc-depth: 2
    code-block-bg: "#f8f8f8"
    code-block-border-left: "#e1e4e5"
    theme: simplex
    number-sections: true
    fig-format: svg
  typst:
    fontsize: 11pt
    margin:
      x: 1in
      y: 1in
    number-sections: true
    fig-format: svg

execute:
  cache: true
  freeze: auto

# Code formatting options
code-overflow: wrap
code-line-numbers: false
code-block-font-size: "0.85em"
---

```{julia}
#| output: false
using Pkg
lab_dir = dirname(@__FILE__)
Pkg.activate(lab_dir)
#Pkg.instantiate() # uncomment this the first time you run the lab to install packages, then comment it back
```





## Question 1 

### 1A

```{julia}

gcm_mean = 20
gcm_std = 3

obs_mean = 15
obs_std = 2

gcm_future_val = 26

corrected_val = obs_mean + (gcm_future_val-gcm_mean)*(obs_std/gcm_std)

println("The corrected value is: ", corrected_val)

```

### 1B


This method corrects the bias within the mean of the GCM as it differs from that of the observations, but scales the bias within the standard deviation.

### 1C

The linear scaling method corrects bias within the mean, but scales bias within the standard deviation.  The skew in the GCM data corresponds to a higher standard deviation than is correct, and linear scaling will not correct this, but will instead exacerbate it.


![Figure for 1C: GCM Distribution, Observed Distribution, and Corrected Distribution](1C_Figure.png)


### 1D

QQ-mapping fixes this problem because, since we are mapping through the quantiles, we're not really looking at the measurement's relation to the mean given the skew as much as we are it's probability of occurrence given whatever that mean and skew is, and then mapping it to a measurement of the same probability within the observed data.  So the skew and the mean don't really matter, their values aren't preserved in the results of our quantile function. 

The role of the quantile function is to map between values and their quantiles. 


## Question 2


### 2A


```{julia}

p_wet = 0.3
p_dry = 0.7

p_3daywet = p_wet^3

println("The probability of getting a 3-day wet spell is ", p_3daywet, " or ", p_3daywet*100,"%")
```

### 2B


```{julia}


p_dry2dry = 0.95
p_dry2wet = 0.05

p_wet2wet = 0.9
p_wet2dry = 0.10

p_markov_3daywet = p_wet*p_wet2wet*p_wet2wet


p_markov_3daywet = round(p_markov_3daywet, digits=5)

println("The probability of getting a 3-day wet spell with the markov model is ", p_markov_3daywet, " or ", p_markov_3daywet*100,"%")

```


### 2C 

The HMM models not the frequency of states, like the k-means model, but the frequency at which one state will tranisition into another, or tranition to itself.  For this reason, the HMM is important for modeling persistence, because in weather, the most likely next state if often the same as or similar to what was just happening. 



## Question 3

### 3A 

The results of our PCA are: 

$(X_{obs} - \mu)V_k = Z$

Or, for one row of c_1: 

$(x_{obs1} - \mu)V_k = c_1$

So in order to obtain the desired image, do algebra to reverse this formula: 

$c_1 V_k^T + \mu = x_{obs1}$

### 3B

We're transforming oru data into the PC space in order to cluster them, so the centroid of the cluster in PC space will be different from the centroid of that cluster in real data, as these are spaces with different dimensionalities and organizations.  When we only use $k = 4$ PC's instrad of all $p = 500$ dimensions, we are eliminating a tremendous amount of data.  This data is often noisy, and we can gain insights from looking at our data set without it, but it is still data we are losing. 


### 3C 

Option A is actually leveraging the information that we gained about trends by doing the PC analysis.  Option B is throwing a lot of that advantage out the window by still including what could be interpreted as noisy, background data, and taking us out of the PC space.  Option A is ther actual mean of Cluster 1, which is what we want, vs option B, which is the mean of the days that were assigned to cluster 1. 

## Question 4 

### 4A 


AIC is Akaike Information Criterion, and BIC is Bayesian Information Criterion.  Both indicate better model performance as lower scores, so using AIC, you would select the complex model, and using BIC, you would select the simple model. 

### 4B 

AIC is: 

$AIC = -2\ln(L) + 2k$

Where L is the maximized likelihood function, and k is our number of parameters in the model.  For comparison, BIC is: 

$BIC = -2\ln(L) + k\ln(n)$

Where n is our number of observations in the data set.  Once n is 8 or larger, BIC will impose a larger penalty on having more parameters than AIC.  This is likely why AIC and BIC disagree in this case, because we have 8 or more observations, and BIC is penalizing the compelex model for having more parameters then the simple one. 

### 4C 


The "M-open" perspective is that none of the models are a true or perfect representaition of the data-generating process.  This assumption would lead us to believe that neither model is suitable to project climate change impact assesment 50 years into the future, especially with the added context that our models have been trained on data from the past, and likely have not been fitted to the unobserved trends of the future.  

## Question 5

### 5A 

Using Multiplicative Delta method: 

```{julia}

gcm_95 = 40
gcm_50 = 10
obs_95 = 50
obs_50 = 12

gcm_future_95 = 48
gcm_future_50 = 11

delta = obs_50/gcm_50 

corrected_gcm_future_95 = gcm_future_95*delta
corrected_gcm_future_50 = gcm_future_50*delta


println("Corrected value for 95th percentile for the future is: ", corrected_gcm_future_95, " mm")
println("Corrected value for 50th percentile for the future is: ", corrected_gcm_future_50, " mm")
```


### 5B

Using Quantile Delta Mapping: 

```{julia}

delta_50 = obs_50/gcm_50 
delta_95 = obs_95/gcm_95

q_corrected_gcm_future_95 = gcm_future_95*delta_95
q_corrected_gcm_future_50 = gcm_future_50*delta_50

println("QDM corrected value for 95th percentile for the future is: ", q_corrected_gcm_future_95, " mm")
println("QDM corrected value for 50th percentile for the future is: ", q_corrected_gcm_future_50, " mm")


```

