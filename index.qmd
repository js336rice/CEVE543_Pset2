---
title: "CEVE 543 Fall 2025 Pset 2"

author: Jonah Schaechter
date: "2025-11-18"
type: "Pset"
module: 2

engine: julia


format:
  html:
    toc: true
    toc-depth: 2
    code-block-bg: "#f8f8f8"
    code-block-border-left: "#e1e4e5"
    theme: simplex
    number-sections: true
    fig-format: svg
  typst:
    fontsize: 11pt
    margin:
      x: 1in
      y: 1in
    number-sections: true
    fig-format: svg

execute:
  cache: true
  freeze: auto

# Code formatting options
code-overflow: wrap
code-line-numbers: false
code-block-font-size: "0.85em"
---

```{julia}
#| output: false
using Pkg
lab_dir = dirname(@__FILE__)
Pkg.activate(lab_dir)
#Pkg.instantiate() # uncomment this the first time you run the lab to install packages, then comment it back
```





## Question 1 

### 1A

```{julia}

gcm_mean = 20
gcm_std = 3

obs_mean = 15
obs_std = 2

gcm_future_val = 26

corrected_val = obs_mean + (gcm_future_val-gcm_mean)*(obs_std/gcm_std)

println("The corrected value is: ", corrected_val)

```

### 1B


This method corrects the bias within the mean of the GCM as it differs from that of the observations, but scales the bias within the standard deviation.

### 1C

The linear scaling method corrects bias within the mean, but scales bias within the standard deviation.  The skew in the GCM data corresponds to a higher standard deviation than is correct, and linear scaling will not correct this, but will instead exacerbate it.


![Figure for 1C: GCM Distribution, Observed Distribution, and Corrected Distribution](1C_Figure.png)


### 1D

QQ-mapping fixes this problem because, since we are mapping through the quantiles, we're not really looking at the measurement's relation to the mean given the skew as much as we are it's probability of occurrence given whatever that mean and skew is, and then mapping it to a measurement of the same probability within the observed data.  So the skew and the mean don't really matter, their values aren't preserved in the results of our quantile function. 

The role of the quantile function is to map between values and their quantiles. 


## Question 2


### 2A


```{julia}

p_wet = 0.3
p_dry = 0.7

p_3daywet = p_wet^3

println("The probability of getting a 3-day wet spell is ", p_3daywet, " or ", p_3daywet*100,"%")
```

### 2B


```{julia}


p_dry2dry = 0.95
p_dry2wet = 0.05

p_wet2wet = 0.9
p_wet2dry = 0.10

p_markov_3daywet = p_wet*p_wet2wet*p_wet2wet


p_markov_3daywet = round(p_markov_3daywet, digits=5)

println("The probability of getting a 3-day wet spell with the markov model is ", p_markov_3daywet, " or ", p_markov_3daywet*100,"%")

```


### 2C 

The HMM models not the frequency of states, like the k-means model, but the frequency at which one state will tranisition into another, or tranition to itself.  For this reason, the HMM is important for modeling persistence, because in weather, the most likely next state if often the same as or similar to what was just happening. 



## Question 3

### 3A 
